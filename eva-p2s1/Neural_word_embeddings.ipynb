{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_word_embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEaiPXGyrJA8",
        "colab_type": "text"
      },
      "source": [
        "# Neural-word-embeddings\n",
        "Name : Venkata Badarinadh Gelli\n",
        "\n",
        "Background :\n",
        "This Assignment we will be using the most popular method Word Embedding to find out how it works \n",
        "\n",
        "Deep Learning for NLP is pattern recognition applied to words, sentences, and paragraphs, in much the same way that computer vision is pattern recognition to pixels.Like all other neural networks, deep-learning models don't take as input raw text: they only work with numeric tensors. Vectorizing text is the process of transforming text into numeric tensors. \n",
        "\n",
        "Requirements :\n",
        "We will use the IMDB database and Glove model to create the word embedding\n",
        "\n",
        "Environment:\n",
        "Development - Colab GPU , Jupyter Notebook Repository : Github\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGyoFkhgyO2G",
        "colab_type": "text"
      },
      "source": [
        "# Import all Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxJ5t5iBrLZ-",
        "colab_type": "code",
        "outputId": "4c1f01a9-2a2f-4cc5-bd54-88be13c72c6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2yD1hQuyYrj",
        "colab_type": "text"
      },
      "source": [
        "# Request to get the IMDB data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwsCLl9rShRI",
        "colab_type": "code",
        "outputId": "ef17ce0e-dc91-423b-adb4-0648715c7c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeeFYYwNLOgo",
        "colab_type": "code",
        "outputId": "cae806b5-1f8f-4b06-c011-6dd86f14a4a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "!wget --no-check-certificate http://mng.bz/0tIo\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-21 13:17:05--  http://mng.bz/0tIo\n",
            "Resolving mng.bz (mng.bz)... 35.166.24.88\n",
            "Connecting to mng.bz (mng.bz)|35.166.24.88|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://mng.bz/0tIo [following]\n",
            "--2020-03-21 13:17:05--  https://mng.bz/0tIo\n",
            "Connecting to mng.bz (mng.bz)|35.166.24.88|:443... connected.\n",
            "WARNING: cannot verify mng.bz's certificate, issued by ‘CN=Go Daddy Secure Certificate Authority - G2,OU=http://certs.godaddy.com/repository/,O=GoDaddy.com\\\\, Inc.,L=Scottsdale,ST=Arizona,C=US’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 301 \n",
            "Location: http://s3.amazonaws.com/text-datasets/aclImdb.zip [following]\n",
            "--2020-03-21 13:17:06--  http://s3.amazonaws.com/text-datasets/aclImdb.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.102.101\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.102.101|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60711700 (58M) [application/zip]\n",
            "Saving to: ‘0tIo’\n",
            "\n",
            "0tIo                100%[===================>]  57.90M  22.0MB/s    in 2.6s    \n",
            "\n",
            "2020-03-21 13:17:09 (22.0 MB/s) - ‘0tIo’ saved [60711700/60711700]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thGWbdrNLT8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q 0tIo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K701fgeWzB5R",
        "colab_type": "text"
      },
      "source": [
        "# Read the IMDB Data and append labels "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQQRfVtxLnS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imdb_dir = '/content/aclImdb'\n",
        "train_dir = os.path.join(imdb_dir, 'train')\n",
        "\n",
        "labels = []\n",
        "texts = []\n",
        "\n",
        "for label_type in ['neg', 'pos']:\n",
        "  dir_name = os.path.join(train_dir, label_type)\n",
        "  for fname in os.listdir(dir_name):\n",
        "    #print(fname)\n",
        "    if fname[-4:] == '.txt':\n",
        "      #print('opening file', fname)\n",
        "      f = open(os.path.join(dir_name, fname))\n",
        "      texts.append(f.read())\n",
        "      f.close()\n",
        "      if label_type == 'neg':\n",
        "        labels.append(0)\n",
        "      else:\n",
        "        labels.append(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3OwaU8tzMDS",
        "colab_type": "text"
      },
      "source": [
        "# Print the Length of the texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7orZNf4r5cz6",
        "colab_type": "code",
        "outputId": "9eb4afc5-1602-4e46-91df-6a1b1492a97f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(texts))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMrtToDz5fzU",
        "colab_type": "code",
        "outputId": "a92882f8-46e8-4192-8260-56c110840b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "maxlen = 100                  # Define the maximum length of each record \n",
        "training_samples = 8000       # Define the number of samples to be taken for training\n",
        "validation_samples = 10000    # Define number of validation samples. In this we will see that even less number of training samples than validation data also perform not very bad \n",
        "max_words = 10000             # Creates a tokenizer, configured to only take into account the 10,000 most common words\n",
        "\n",
        "\n",
        "# Create Tokenizer , Fit it to the Texts and create a sequence of texts from the tokenizer \n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "# Create a dictionary of the word and respective numeric index value \n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "# Define the sequence with the numeric indexes \n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "# variable for labels\n",
        "labels = np.asarray(labels)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "# Shuffle the indices as the data are normally in group for each label \n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "# Segreegate data for training and validation \n",
        "x_train = data[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "\n",
        "x_val = data[training_samples: training_samples + validation_samples]\n",
        "y_val = labels[training_samples: training_samples + validation_samples]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 88582 unique tokens.\n",
            "Shape of data tensor: (25000, 100)\n",
            "Shape of label tensor: (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLxlohYc3lA2",
        "colab_type": "text"
      },
      "source": [
        "# Download the Glove model . \n",
        "Here we are downloading the Glove6B model as our environment may not support heavier models than this due to memory constraints "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBdzSAxl5xNV",
        "colab_type": "code",
        "outputId": "09b0f060-407c-40bf-fc24-13eb23e61b86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-21 13:20:35--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-03-21 13:20:35--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-03-21 13:20:36--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.14MB/s    in 6m 29s  \n",
            "\n",
            "2020-03-21 13:27:05 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx35i3wG6Ch-",
        "colab_type": "code",
        "outputId": "91523f39-1ea4-4c11-cb59-145868d15cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!unzip glove*.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbXwoeDA337T",
        "colab_type": "text"
      },
      "source": [
        "We will use the glove model for 100 dimension . We can use heavier models but due to memory constraints we are using this one "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tit5ZmAa7kBE",
        "colab_type": "text"
      },
      "source": [
        "# Read the embedding file and load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkq4BSOh8i_q",
        "colab_type": "code",
        "outputId": "d7c26a91-3670-48ce-dc05-2fab5fd64eb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "glove_dir = '/content'\n",
        "embeddings_index = {}\n",
        "\n",
        "embedding_dim = 100\n",
        "embedding_file_name = 'glove.6B.100d.txt'\n",
        "\n",
        "f = open(os.path.join(glove_dir, embedding_file_name ))\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' %len(embeddings_index))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNBxoMiS77DZ",
        "colab_type": "text"
      },
      "source": [
        "# Let's display some to see how it looks "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFmGdRjb81P1",
        "colab_type": "code",
        "outputId": "e36f02fe-4641-4bed-98f0-446a6780c1b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(list(embeddings_index.keys())[0:100])\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the', ',', '.', 'of', 'to', 'and', 'in', 'a', '\"', \"'s\", 'for', '-', 'that', 'on', 'is', 'was', 'said', 'with', 'he', 'as', 'it', 'by', 'at', '(', ')', 'from', 'his', \"''\", '``', 'an', 'be', 'has', 'are', 'have', 'but', 'were', 'not', 'this', 'who', 'they', 'had', 'i', 'which', 'will', 'their', ':', 'or', 'its', 'one', 'after', 'new', 'been', 'also', 'we', 'would', 'two', 'more', \"'\", 'first', 'about', 'up', 'when', 'year', 'there', 'all', '--', 'out', 'she', 'other', 'people', \"n't\", 'her', 'percent', 'than', 'over', 'into', 'last', 'some', 'government', 'time', '$', 'you', 'years', 'if', 'no', 'world', 'can', 'three', 'do', ';', 'president', 'only', 'state', 'million', 'could', 'us', 'most', '_', 'against', 'u.s.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L_iL1EN7-4h",
        "colab_type": "text"
      },
      "source": [
        "# Steps\n",
        "1. Define a  blank Embedding_matrix\n",
        "2. Update Embedding matrix by reading sequentially using the Embedding Index "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vc5kuDW8-9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i < max_words:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector   # Words not found in the embedding index will be all zeros"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0XiaMRC85fB",
        "colab_type": "text"
      },
      "source": [
        "# Define a Sequential model \n",
        "The Model consisits of 2 fully connected layers . This is one of the simple layers used as the intention here is to understand how word embedding works and not to go deeep models to improve the accuracy of the model. We will look into model training and performance improvement later\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6qg35_D9HLr",
        "colab_type": "code",
        "outputId": "4f8c329c-c11c-4b2e-ca5d-961f94d3cdce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                320032    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,320,065\n",
            "Trainable params: 1,320,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QPbiuI59iuf",
        "colab_type": "text"
      },
      "source": [
        "1. Set the weights to the Embedding matrix \n",
        "2.  freeze the Embedding layer (set its trainable attribute to False) as we are using a pretrained model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSUOohBQ9J3r",
        "colab_type": "code",
        "outputId": "69db7b58-ac26-4200-ec68-3bdfd79bfb67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "\n",
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jzwr679CSBl",
        "colab_type": "text"
      },
      "source": [
        "# Compile and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLdONR1n9MgG",
        "colab_type": "code",
        "outputId": "4da19161-6235-4400-8fb7-d5987f20aad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(x_val, y_val)\n",
        "                    )\n",
        "\n",
        "model.save_weights('pre_trained_glove_model.h5')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 8000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "8000/8000 [==============================] - 3s 375us/step - loss: 0.7189 - acc: 0.5615 - val_loss: 0.6259 - val_acc: 0.6544\n",
            "Epoch 2/100\n",
            "8000/8000 [==============================] - 1s 138us/step - loss: 0.6028 - acc: 0.6785 - val_loss: 0.6633 - val_acc: 0.6172\n",
            "Epoch 3/100\n",
            "8000/8000 [==============================] - 1s 137us/step - loss: 0.5052 - acc: 0.7568 - val_loss: 0.5863 - val_acc: 0.6912\n",
            "Epoch 4/100\n",
            "8000/8000 [==============================] - 1s 134us/step - loss: 0.4309 - acc: 0.8054 - val_loss: 0.5820 - val_acc: 0.7046\n",
            "Epoch 5/100\n",
            "8000/8000 [==============================] - 1s 136us/step - loss: 0.3644 - acc: 0.8433 - val_loss: 0.5971 - val_acc: 0.7024\n",
            "Epoch 6/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 0.3176 - acc: 0.8663 - val_loss: 0.6394 - val_acc: 0.7049\n",
            "Epoch 7/100\n",
            "8000/8000 [==============================] - 1s 132us/step - loss: 0.2531 - acc: 0.8939 - val_loss: 0.6822 - val_acc: 0.7003\n",
            "Epoch 8/100\n",
            "8000/8000 [==============================] - 1s 133us/step - loss: 0.2014 - acc: 0.9243 - val_loss: 0.7901 - val_acc: 0.6981\n",
            "Epoch 9/100\n",
            "8000/8000 [==============================] - 1s 136us/step - loss: 0.1671 - acc: 0.9402 - val_loss: 0.7990 - val_acc: 0.6906\n",
            "Epoch 10/100\n",
            "8000/8000 [==============================] - 1s 135us/step - loss: 0.1293 - acc: 0.9536 - val_loss: 0.8566 - val_acc: 0.6975\n",
            "Epoch 11/100\n",
            "8000/8000 [==============================] - 1s 133us/step - loss: 0.0934 - acc: 0.9705 - val_loss: 1.0402 - val_acc: 0.6834\n",
            "Epoch 12/100\n",
            "8000/8000 [==============================] - 1s 142us/step - loss: 0.0650 - acc: 0.9798 - val_loss: 1.0880 - val_acc: 0.6877\n",
            "Epoch 13/100\n",
            "8000/8000 [==============================] - 1s 146us/step - loss: 0.0486 - acc: 0.9842 - val_loss: 1.0932 - val_acc: 0.6930\n",
            "Epoch 14/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 0.0427 - acc: 0.9872 - val_loss: 1.2242 - val_acc: 0.6931\n",
            "Epoch 15/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 0.0238 - acc: 0.9919 - val_loss: 1.4501 - val_acc: 0.6809\n",
            "Epoch 16/100\n",
            "8000/8000 [==============================] - 1s 141us/step - loss: 0.0243 - acc: 0.9931 - val_loss: 1.4559 - val_acc: 0.6802\n",
            "Epoch 17/100\n",
            "8000/8000 [==============================] - 1s 141us/step - loss: 0.0233 - acc: 0.9921 - val_loss: 2.3631 - val_acc: 0.6249\n",
            "Epoch 18/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 0.0128 - acc: 0.9960 - val_loss: 1.4753 - val_acc: 0.6872\n",
            "Epoch 19/100\n",
            "8000/8000 [==============================] - 1s 138us/step - loss: 0.0246 - acc: 0.9916 - val_loss: 1.4450 - val_acc: 0.6927\n",
            "Epoch 20/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 0.0098 - acc: 0.9967 - val_loss: 2.7628 - val_acc: 0.6184\n",
            "Epoch 21/100\n",
            "8000/8000 [==============================] - 1s 142us/step - loss: 0.0125 - acc: 0.9959 - val_loss: 1.6895 - val_acc: 0.6890\n",
            "Epoch 22/100\n",
            "8000/8000 [==============================] - 1s 139us/step - loss: 0.0101 - acc: 0.9961 - val_loss: 1.7075 - val_acc: 0.6887\n",
            "Epoch 23/100\n",
            "8000/8000 [==============================] - 1s 133us/step - loss: 0.0102 - acc: 0.9951 - val_loss: 1.6962 - val_acc: 0.6871\n",
            "Epoch 24/100\n",
            "8000/8000 [==============================] - 1s 138us/step - loss: 0.0144 - acc: 0.9955 - val_loss: 1.7983 - val_acc: 0.6894\n",
            "Epoch 25/100\n",
            "8000/8000 [==============================] - 1s 136us/step - loss: 0.0102 - acc: 0.9964 - val_loss: 1.8126 - val_acc: 0.6846\n",
            "Epoch 26/100\n",
            "8000/8000 [==============================] - 1s 134us/step - loss: 0.0124 - acc: 0.9967 - val_loss: 1.9192 - val_acc: 0.6839\n",
            "Epoch 27/100\n",
            "8000/8000 [==============================] - 1s 138us/step - loss: 0.0160 - acc: 0.9949 - val_loss: 1.8362 - val_acc: 0.6875\n",
            "Epoch 28/100\n",
            "8000/8000 [==============================] - 1s 133us/step - loss: 0.0099 - acc: 0.9966 - val_loss: 1.8690 - val_acc: 0.6879\n",
            "Epoch 29/100\n",
            "8000/8000 [==============================] - 1s 137us/step - loss: 0.0050 - acc: 0.9988 - val_loss: 1.9049 - val_acc: 0.6898\n",
            "Epoch 30/100\n",
            "8000/8000 [==============================] - 1s 141us/step - loss: 0.0064 - acc: 0.9981 - val_loss: 2.0167 - val_acc: 0.6924\n",
            "Epoch 31/100\n",
            "8000/8000 [==============================] - 1s 134us/step - loss: 0.0068 - acc: 0.9979 - val_loss: 2.0498 - val_acc: 0.6872\n",
            "Epoch 32/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 0.0103 - acc: 0.9964 - val_loss: 2.0280 - val_acc: 0.6909\n",
            "Epoch 33/100\n",
            "8000/8000 [==============================] - 1s 137us/step - loss: 0.0120 - acc: 0.9966 - val_loss: 1.9756 - val_acc: 0.6889\n",
            "Epoch 34/100\n",
            "8000/8000 [==============================] - 1s 135us/step - loss: 0.0071 - acc: 0.9973 - val_loss: 2.0378 - val_acc: 0.6878\n",
            "Epoch 35/100\n",
            "8000/8000 [==============================] - 1s 132us/step - loss: 0.0052 - acc: 0.9988 - val_loss: 2.1703 - val_acc: 0.6857\n",
            "Epoch 36/100\n",
            "8000/8000 [==============================] - 1s 132us/step - loss: 0.0037 - acc: 0.9988 - val_loss: 2.2367 - val_acc: 0.6828\n",
            "Epoch 37/100\n",
            "8000/8000 [==============================] - 1s 135us/step - loss: 0.0027 - acc: 0.9988 - val_loss: 2.2974 - val_acc: 0.6878\n",
            "Epoch 38/100\n",
            "8000/8000 [==============================] - 1s 134us/step - loss: 0.0017 - acc: 0.9992 - val_loss: 2.2555 - val_acc: 0.6867\n",
            "Epoch 39/100\n",
            "8000/8000 [==============================] - 1s 135us/step - loss: 0.0032 - acc: 0.9988 - val_loss: 2.2868 - val_acc: 0.6880\n",
            "Epoch 40/100\n",
            "8000/8000 [==============================] - 1s 132us/step - loss: 0.0088 - acc: 0.9981 - val_loss: 2.4096 - val_acc: 0.6824\n",
            "Epoch 41/100\n",
            "8000/8000 [==============================] - 1s 137us/step - loss: 0.0042 - acc: 0.9989 - val_loss: 2.3175 - val_acc: 0.6825\n",
            "Epoch 42/100\n",
            "8000/8000 [==============================] - 1s 135us/step - loss: 0.0035 - acc: 0.9986 - val_loss: 2.3952 - val_acc: 0.6854\n",
            "Epoch 43/100\n",
            "8000/8000 [==============================] - 1s 134us/step - loss: 0.0032 - acc: 0.9990 - val_loss: 2.4869 - val_acc: 0.6840\n",
            "Epoch 44/100\n",
            "8000/8000 [==============================] - 1s 137us/step - loss: 0.0048 - acc: 0.9984 - val_loss: 2.4161 - val_acc: 0.6839\n",
            "Epoch 45/100\n",
            "8000/8000 [==============================] - 1s 133us/step - loss: 0.0024 - acc: 0.9991 - val_loss: 2.5353 - val_acc: 0.6860\n",
            "Epoch 46/100\n",
            "8000/8000 [==============================] - 1s 139us/step - loss: 0.0060 - acc: 0.9988 - val_loss: 2.4188 - val_acc: 0.6798\n",
            "Epoch 47/100\n",
            "8000/8000 [==============================] - 1s 134us/step - loss: 3.3840e-04 - acc: 1.0000 - val_loss: 2.5170 - val_acc: 0.6848\n",
            "Epoch 48/100\n",
            "8000/8000 [==============================] - 1s 139us/step - loss: 0.0057 - acc: 0.9985 - val_loss: 2.5140 - val_acc: 0.6849\n",
            "Epoch 49/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 6.0534e-04 - acc: 0.9999 - val_loss: 2.5899 - val_acc: 0.6846\n",
            "Epoch 50/100\n",
            "8000/8000 [==============================] - 1s 139us/step - loss: 0.0040 - acc: 0.9996 - val_loss: 2.5529 - val_acc: 0.6872\n",
            "Epoch 51/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 0.0072 - acc: 0.9979 - val_loss: 2.6328 - val_acc: 0.6839\n",
            "Epoch 52/100\n",
            "8000/8000 [==============================] - 1s 137us/step - loss: 0.0011 - acc: 0.9992 - val_loss: 2.5826 - val_acc: 0.6856\n",
            "Epoch 53/100\n",
            "8000/8000 [==============================] - 1s 139us/step - loss: 5.5066e-04 - acc: 0.9998 - val_loss: 2.6386 - val_acc: 0.6857\n",
            "Epoch 54/100\n",
            "8000/8000 [==============================] - 1s 138us/step - loss: 0.0024 - acc: 0.9991 - val_loss: 2.7009 - val_acc: 0.6865\n",
            "Epoch 55/100\n",
            "8000/8000 [==============================] - 1s 139us/step - loss: 0.0025 - acc: 0.9996 - val_loss: 2.6653 - val_acc: 0.6860\n",
            "Epoch 56/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 0.0027 - acc: 0.9991 - val_loss: 2.7785 - val_acc: 0.6852\n",
            "Epoch 57/100\n",
            "8000/8000 [==============================] - 1s 139us/step - loss: 0.0019 - acc: 0.9994 - val_loss: 2.7234 - val_acc: 0.6838\n",
            "Epoch 58/100\n",
            "8000/8000 [==============================] - 1s 137us/step - loss: 0.0031 - acc: 0.9992 - val_loss: 2.6940 - val_acc: 0.6869\n",
            "Epoch 59/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 0.0022 - acc: 0.9995 - val_loss: 2.7722 - val_acc: 0.6878\n",
            "Epoch 60/100\n",
            "8000/8000 [==============================] - 1s 139us/step - loss: 0.0058 - acc: 0.9984 - val_loss: 2.7165 - val_acc: 0.6829\n",
            "Epoch 61/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 0.0028 - acc: 0.9994 - val_loss: 2.8690 - val_acc: 0.6839\n",
            "Epoch 62/100\n",
            "8000/8000 [==============================] - 1s 134us/step - loss: 5.7941e-04 - acc: 0.9998 - val_loss: 2.7771 - val_acc: 0.6816\n",
            "Epoch 63/100\n",
            "8000/8000 [==============================] - 1s 135us/step - loss: 4.9953e-05 - acc: 1.0000 - val_loss: 2.8630 - val_acc: 0.6831\n",
            "Epoch 64/100\n",
            "8000/8000 [==============================] - 1s 135us/step - loss: 4.1367e-04 - acc: 0.9998 - val_loss: 2.8717 - val_acc: 0.6864\n",
            "Epoch 65/100\n",
            "8000/8000 [==============================] - 1s 134us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 2.9026 - val_acc: 0.6822\n",
            "Epoch 66/100\n",
            "8000/8000 [==============================] - 1s 136us/step - loss: 0.0024 - acc: 0.9992 - val_loss: 2.7713 - val_acc: 0.6826\n",
            "Epoch 67/100\n",
            "8000/8000 [==============================] - 1s 139us/step - loss: 5.7691e-04 - acc: 0.9996 - val_loss: 2.7483 - val_acc: 0.6812\n",
            "Epoch 68/100\n",
            "8000/8000 [==============================] - 1s 137us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 2.8893 - val_acc: 0.6825\n",
            "Epoch 69/100\n",
            "8000/8000 [==============================] - 1s 133us/step - loss: 3.1857e-05 - acc: 1.0000 - val_loss: 2.9862 - val_acc: 0.6871\n",
            "Epoch 70/100\n",
            "8000/8000 [==============================] - 1s 137us/step - loss: 2.8381e-04 - acc: 0.9999 - val_loss: 2.9694 - val_acc: 0.6865\n",
            "Epoch 71/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 0.0015 - acc: 0.9995 - val_loss: 3.1142 - val_acc: 0.6818\n",
            "Epoch 72/100\n",
            "8000/8000 [==============================] - 1s 133us/step - loss: 4.2679e-06 - acc: 1.0000 - val_loss: 3.0395 - val_acc: 0.6799\n",
            "Epoch 73/100\n",
            "8000/8000 [==============================] - 1s 133us/step - loss: 9.3509e-04 - acc: 0.9999 - val_loss: 2.9975 - val_acc: 0.6859\n",
            "Epoch 74/100\n",
            "8000/8000 [==============================] - 1s 135us/step - loss: 8.7049e-04 - acc: 0.9998 - val_loss: 2.9922 - val_acc: 0.6858\n",
            "Epoch 75/100\n",
            "8000/8000 [==============================] - 1s 135us/step - loss: 1.9393e-07 - acc: 1.0000 - val_loss: 3.0435 - val_acc: 0.6872\n",
            "Epoch 76/100\n",
            "8000/8000 [==============================] - 1s 137us/step - loss: 1.1271e-07 - acc: 1.0000 - val_loss: 3.0380 - val_acc: 0.6862\n",
            "Epoch 77/100\n",
            "8000/8000 [==============================] - 1s 133us/step - loss: 1.1031e-07 - acc: 1.0000 - val_loss: 3.0575 - val_acc: 0.6864\n",
            "Epoch 78/100\n",
            "8000/8000 [==============================] - 1s 138us/step - loss: 1.0994e-07 - acc: 1.0000 - val_loss: 3.0657 - val_acc: 0.6867\n",
            "Epoch 79/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 1.0987e-07 - acc: 1.0000 - val_loss: 3.0729 - val_acc: 0.6861\n",
            "Epoch 80/100\n",
            "8000/8000 [==============================] - 1s 139us/step - loss: 1.0982e-07 - acc: 1.0000 - val_loss: 3.0794 - val_acc: 0.6863\n",
            "Epoch 81/100\n",
            "8000/8000 [==============================] - 1s 138us/step - loss: 1.0978e-07 - acc: 1.0000 - val_loss: 3.0800 - val_acc: 0.6863\n",
            "Epoch 82/100\n",
            "8000/8000 [==============================] - 1s 133us/step - loss: 1.0978e-07 - acc: 1.0000 - val_loss: 3.0799 - val_acc: 0.6863\n",
            "Epoch 83/100\n",
            "8000/8000 [==============================] - 1s 136us/step - loss: 1.0976e-07 - acc: 1.0000 - val_loss: 3.0847 - val_acc: 0.6873\n",
            "Epoch 84/100\n",
            "8000/8000 [==============================] - 1s 134us/step - loss: 1.0976e-07 - acc: 1.0000 - val_loss: 3.0845 - val_acc: 0.6874\n",
            "Epoch 85/100\n",
            "8000/8000 [==============================] - 1s 139us/step - loss: 1.0974e-07 - acc: 1.0000 - val_loss: 3.0901 - val_acc: 0.6870\n",
            "Epoch 86/100\n",
            "8000/8000 [==============================] - 1s 135us/step - loss: 1.0974e-07 - acc: 1.0000 - val_loss: 3.0927 - val_acc: 0.6867\n",
            "Epoch 87/100\n",
            "8000/8000 [==============================] - 1s 136us/step - loss: 1.0974e-07 - acc: 1.0000 - val_loss: 3.0921 - val_acc: 0.6874\n",
            "Epoch 88/100\n",
            "8000/8000 [==============================] - 1s 135us/step - loss: 1.0974e-07 - acc: 1.0000 - val_loss: 3.0928 - val_acc: 0.6864\n",
            "Epoch 89/100\n",
            "8000/8000 [==============================] - 1s 135us/step - loss: 1.0974e-07 - acc: 1.0000 - val_loss: 3.0907 - val_acc: 0.6862\n",
            "Epoch 90/100\n",
            "8000/8000 [==============================] - 1s 138us/step - loss: 1.0973e-07 - acc: 1.0000 - val_loss: 3.0924 - val_acc: 0.6867\n",
            "Epoch 91/100\n",
            "8000/8000 [==============================] - 1s 134us/step - loss: 1.0973e-07 - acc: 1.0000 - val_loss: 3.0951 - val_acc: 0.6860\n",
            "Epoch 92/100\n",
            "8000/8000 [==============================] - 1s 135us/step - loss: 1.0973e-07 - acc: 1.0000 - val_loss: 3.0973 - val_acc: 0.6872\n",
            "Epoch 93/100\n",
            "8000/8000 [==============================] - 1s 138us/step - loss: 1.0974e-07 - acc: 1.0000 - val_loss: 3.0936 - val_acc: 0.6869\n",
            "Epoch 94/100\n",
            "8000/8000 [==============================] - 1s 137us/step - loss: 1.0973e-07 - acc: 1.0000 - val_loss: 3.0973 - val_acc: 0.6867\n",
            "Epoch 95/100\n",
            "8000/8000 [==============================] - 1s 134us/step - loss: 1.0974e-07 - acc: 1.0000 - val_loss: 3.0950 - val_acc: 0.6866\n",
            "Epoch 96/100\n",
            "8000/8000 [==============================] - 1s 137us/step - loss: 1.0973e-07 - acc: 1.0000 - val_loss: 3.0976 - val_acc: 0.6865\n",
            "Epoch 97/100\n",
            "8000/8000 [==============================] - 1s 136us/step - loss: 1.0973e-07 - acc: 1.0000 - val_loss: 3.0997 - val_acc: 0.6862\n",
            "Epoch 98/100\n",
            "8000/8000 [==============================] - 1s 133us/step - loss: 1.0972e-07 - acc: 1.0000 - val_loss: 3.1035 - val_acc: 0.6865\n",
            "Epoch 99/100\n",
            "8000/8000 [==============================] - 1s 135us/step - loss: 1.0972e-07 - acc: 1.0000 - val_loss: 3.1008 - val_acc: 0.6863\n",
            "Epoch 100/100\n",
            "8000/8000 [==============================] - 1s 138us/step - loss: 1.0974e-07 - acc: 1.0000 - val_loss: 3.0977 - val_acc: 0.6860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uj9gmyKCanv",
        "colab_type": "text"
      },
      "source": [
        "# Plot the Output to see the performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b93br3b9TMp",
        "colab_type": "code",
        "outputId": "f2f0d250-5be4-4e76-ba6e-bc9965504a06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}